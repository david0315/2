<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Java 爬虫遇到需要登录的网站，该怎么办？' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Java 爬虫遇到需要登录的网站，该怎么办？</center></div><div class='banquan'>原文出处:本文由博客园博主平头哥的技术博文提供。<br/>
原文连接:https://www.cnblogs.com/jamaler/p/11645569.html</div><br>
    <p>这是 Java 网络爬虫系列博文的第二篇，在上一篇 <a href="https://www.cnblogs.com/jamaler/p/11640131.html">Java 网络爬虫，就是这么的简单</a> 中，我们简单的学习了一下如何利用 Java 进行网络爬虫。在这一篇中我们将简单的聊一聊在网络爬虫时，遇到需要登录的网站，我们该怎么办？</p>
<p>在做爬虫时，遇到需要登陆的问题也比较常见，比如写脚本抢票之类的，但凡需要个人信息的都需要登陆，对于这类问题主要有两种解决方式：<strong>一种方式是手动设置 cookie ，就是先在网站上面登录，复制登陆后的 cookies ，在爬虫程序中手动设置 HTTP 请求中的 Cookie 属性，这种方式适用于采集频次不高、采集周期短，因为 cookie 会失效，如果长期采集的话就需要频繁设置 cookie，这不是一种可行的办法，第二种方式就是使用程序模拟登陆，通过模拟登陆获取到 cookies，这种方式适用于长期采集该网站，因为每次采集都会先登陆，这样就不需要担心 cookie 过期的问题。</strong></p>
<p>为了能让大家更好的理解这两种方式的运用，我以获取豆瓣个人主页昵称为例，分别用这两种方式来获取需要登陆后才能看到的信息。获取信息如下图所示：</p>
<p><img src="./images/Java 爬虫遇到需要登录的网站，该怎么办？0.png" /><br />
获取图片中的<code>缺心眼那叫单纯</code>，这个信息显然是需要登陆后才能看到的，这就符合我们的主题啦。接下来分别用上面两种办法来解决这个问题。</p>
<h3 id="手动设置-cookie">手动设置 cookie</h3>
<p>手动设置 cookie 的方式，这种方式比较简单，我们只需要在豆瓣网上登陆，登陆成功后就可以获取到带有用户信息的cookie，豆瓣网登录链接：<code>https://accounts.douban.com/passport/login</code>。如下图所示：<br />
<img src="./images/Java 爬虫遇到需要登录的网站，该怎么办？1.png" /><br />
图中的这个 cookie 就携带了用户信息，我们只需要在请求时携带这个 cookie 就可以查看到需要登陆后才能查看到的信息。我们用 Jsoup 来模拟一下手动设置 cookie 方式，具体代码如下：</p>
<pre><code><code>/**
 * 手动设置 cookies
 * 先从网站上登录，然后查看 request headers 里面的 cookies
 * @param url
 * @throws IOException
 */
public void setCookies(String url) throws IOException {

    Document document = Jsoup.connect(url)
            // 手动设置cookies
            .header(&quot;Cookie&quot;, &quot;your cookies&quot;)
            .get();
    //
    if (document != null) {
        // 获取豆瓣昵称节点
        Element element = document.select(&quot;.info h1&quot;).first();
        if (element == null) {
            System.out.println(&quot;没有找到 .info h1 标签&quot;);
            return;
        }
        // 取出豆瓣节点昵称
        String userName = element.ownText();
        System.out.println(&quot;豆瓣我的网名为：&quot; + userName);
    } else {
        System.out.println(&quot;出错啦！！！！！&quot;);
    }
}</code></code></pre>
<p>从代码中可以看出跟不需要登陆的网站没什么区别，只是多了一个<code>.header(&quot;Cookie&quot;, &quot;your cookies&quot;)</code>，我们把浏览器中的 cookie 复制到这里即可，编写 main 方法</p>
<pre><code><code>public static void main(String[] args) throws Exception {
    // 个人中心url
    String user_info_url = &quot;https://www.douban.com/people/150968577/&quot;;
    new CrawleLogin().setCookies(user_info_url);</code></code></pre>
<p>运行 main 得到结果如下：<br />
<img src="./images/Java 爬虫遇到需要登录的网站，该怎么办？2.png" /><br />
可以看出我们成功获取到了<code>缺心眼那叫单纯</code>，这说明我们设置的 cookie 是有效的，成功的拿到了需要登陆的数据。这种方式是真的比较简单，唯一的不足就是需要频繁的更换 cookie，因为 cookie 会失效，这让你使用起来就不是很爽啦。</p>
<h3 id="模拟登陆方式">模拟登陆方式</h3>
<p>模拟登陆的方式可以解决手动设置 cookie 方式的不足之处，但同时也引入了比较复杂的问题，现在的验证码形形色色、五花八门，很多都富有挑战性，比如在一堆图片中操作某类图片，这个还是非常有难度，不是随便就能够编写出来。所以对于使用哪种方式这个就需要开发者自己去衡量利弊啦。今天我们用到的豆瓣网，在登陆的时候就没有验证码，对于这种没有验证码的还是比较简单的，<strong>关于模拟登陆方式最重要的就是找到真正的登陆请求、登陆需要的参数。</strong> 这个我们就只能取巧了，我们先在登陆界面输入错误的账号密码，这样页面将不会跳转，所以我们就能够轻而易举的找到登陆请求。我来演示一下豆瓣网登陆查找登陆链接，我们在登陆界面输入错误的用户名和密码，点击登陆后，在 network 查看发起的请求链接，如下图所示：<br />
<img src="./images/Java 爬虫遇到需要登录的网站，该怎么办？3.png" /><br />
从 network 中我们可以查看到豆瓣网的登陆链接为<code>https://accounts.douban.com/j/mobile/login/basic</code>，需要的参数有五个，具体参数查看图中的 Form Data，有了这些之后，我们就能够构造请求模拟登陆啦。登陆后进行后续操作，接下来我们就用 Jsoup 来模拟登陆到获取豆瓣主页昵称，具体代码如下：</p>
<pre><code><code>/**
 * Jsoup 模拟登录豆瓣 访问个人中心
 * 在豆瓣登录时先输入一个错误的账号密码，查看到登录所需要的参数
 * 先构造登录请求参数，成功后获取到cookies
 * 设置request cookies，再次请求
 * @param loginUrl 登录url
 * @param userInfoUrl 个人中心url
 * @throws IOException
 */
public void jsoupLogin(String loginUrl,String userInfoUrl)  throws IOException {

    // 构造登陆参数
    Map&lt;String,String&gt; data = new HashMap&lt;&gt;();
    data.put(&quot;name&quot;,&quot;your_account&quot;);
    data.put(&quot;password&quot;,&quot;your_password&quot;);
    data.put(&quot;remember&quot;,&quot;false&quot;);
    data.put(&quot;ticket&quot;,&quot;&quot;);
    data.put(&quot;ck&quot;,&quot;&quot;);
    Connection.Response login = Jsoup.connect(loginUrl)
            .ignoreContentType(true) // 忽略类型验证
            .followRedirects(false) // 禁止重定向
            .postDataCharset(&quot;utf-8&quot;)
            .header(&quot;Upgrade-Insecure-Requests&quot;,&quot;1&quot;)
            .header(&quot;Accept&quot;,&quot;application/json&quot;)
            .header(&quot;Content-Type&quot;,&quot;application/x-www-form-urlencoded&quot;)
            .header(&quot;X-Requested-With&quot;,&quot;XMLHttpRequest&quot;)
            .header(&quot;User-Agent&quot;,&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot;)
            .data(data)
            .method(Connection.Method.POST)
            .execute();
    login.charset(&quot;UTF-8&quot;);
    // login 中已经获取到登录成功之后的cookies
    // 构造访问个人中心的请求
    Document document = Jsoup.connect(userInfoUrl)
            // 取出login对象里面的cookies
            .cookies(login.cookies())
            .get();
    if (document != null) {
        Element element = document.select(&quot;.info h1&quot;).first();
        if (element == null) {
            System.out.println(&quot;没有找到 .info h1 标签&quot;);
            return;
        }
        String userName = element.ownText();
        System.out.println(&quot;豆瓣我的网名为：&quot; + userName);
    } else {
        System.out.println(&quot;出错啦！！！！！&quot;);
    }
}</code></code></pre>
<p>这段代码分两段，前一段是模拟登陆，后一段是解析豆瓣主页，在这段代码中发起了两次请求，第一次请求是模拟登陆获取到 cookie，第二次请求时携带第一次模拟登陆后获取的cookie，这样也可以访问需要登陆的页面，修改 main 方法</p>
<pre><code><code>public static void main(String[] args) throws Exception {
    // 个人中心url
    String user_info_url = &quot;https://www.douban.com/people/150968577/&quot;;

    // 登陆接口
    String login_url = &quot;https://accounts.douban.com/j/mobile/login/basic&quot;;

    // new CrawleLogin().setCookies(user_info_url);
    new CrawleLogin().jsoupLogin(login_url,user_info_url);
}</code></code></pre>
<p>运行 main 方法，得到如下结果：<br />
<img src="./images/Java 爬虫遇到需要登录的网站，该怎么办？2.png" /><br />
模拟登陆的方式也成功的获取到了网名<code>缺心眼那叫单纯</code>，虽然这已经是最简单的模拟登陆啦，从代码量上就可以看出它比设置 cookie 要复杂很多，对于其他有验证码的登陆，我就不在这里介绍了，第一是我在这方面也没什么经验，第二是这个实现起来比较复杂，会涉及到一些算法和一些辅助工具的使用，有兴趣的朋友可以参考崔庆才老师的博客研究研究。模拟登陆写起来虽然比较复杂，但是只要你编写好之后，你就能够一劳永逸，如果你需要长期采集需要登陆的信息，这个还是值得你的做的。</p>
<p>除了使用 jsoup 模拟登陆外，我们还可以使用 httpclient 模拟登陆，httpclient 模拟登陆没有 Jsoup 那么复杂，因为 httpclient 能够像浏览器一样保存 session 会话，这样登陆之后就保存下了 cookie ，在同一个 httpclient 内请求就会带上 cookie 啦。httpclient 模拟登陆代码如下：</p>
<pre><code><code>/**
 * httpclient 的方式模拟登录豆瓣
 * httpclient 跟jsoup差不多，不同的地方在于 httpclient 有session的概念
 * 在同一个httpclient 内不需要设置cookies ，会默认缓存下来
 * @param loginUrl
 * @param userInfoUrl
 */
public void httpClientLogin(String loginUrl,String userInfoUrl) throws Exception{

    CloseableHttpClient httpclient = HttpClients.createDefault();
    HttpUriRequest login = RequestBuilder.post()
            .setUri(new URI(loginUrl))// 登陆url
            .setHeader(&quot;Upgrade-Insecure-Requests&quot;,&quot;1&quot;)
            .setHeader(&quot;Accept&quot;,&quot;application/json&quot;)
            .setHeader(&quot;Content-Type&quot;,&quot;application/x-www-form-urlencoded&quot;)
            .setHeader(&quot;X-Requested-With&quot;,&quot;XMLHttpRequest&quot;)
            .setHeader(&quot;User-Agent&quot;,&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot;)
            // 设置账号信息
            .addParameter(&quot;name&quot;,&quot;your_account&quot;)
            .addParameter(&quot;password&quot;,&quot;your_password&quot;)
            .addParameter(&quot;remember&quot;,&quot;false&quot;)
            .addParameter(&quot;ticket&quot;,&quot;&quot;)
            .addParameter(&quot;ck&quot;,&quot;&quot;)
            .build();
    // 模拟登陆
    CloseableHttpResponse response = httpclient.execute(login);
    if (response.getStatusLine().getStatusCode() == 200){
        // 构造访问个人中心请求
        HttpGet httpGet = new HttpGet(userInfoUrl);
        CloseableHttpResponse user_response = httpclient.execute(httpGet);
        HttpEntity entity = user_response.getEntity();
        //
        String body = EntityUtils.toString(entity, &quot;utf-8&quot;);

        // 偷个懒，直接判断 缺心眼那叫单纯 是否存在字符串中
        System.out.println(&quot;缺心眼那叫单纯是否查找到？&quot;+(body.contains(&quot;缺心眼那叫单纯&quot;)));
    }else {
        System.out.println(&quot;httpclient 模拟登录豆瓣失败了!!!!&quot;);
    }
}</code></code></pre>
<p>运行这段代码，返回的结果也是 true。</p>
<p>有关 Java 爬虫遇到登陆问题就聊得差不多啦，来总结一下：<strong>对于爬虫遇到登陆问题有两种解决办法，一种是手动设置cookie，这种方式适用于短暂性采集或者一次性采集，成本较低。另一种方式是模拟登陆的方式，这种方式适用于长期采集的网站，因为模拟登陆的代价还是蛮高的，特别是一些变态的验证码，好处就是能够让你一劳永逸</strong></p>
<p>以上就是 Java 爬虫时遇到登陆问题相关知识分享，希望对你有所帮助，下一篇是关于爬虫是遇到数据异步加载的问题。如果你对爬虫感兴趣，不妨关注一波，相互学习，相互进步</p>
<p>源代码：<a href="https://github.com/BinaryBall/java-base/blob/master/crawler/src/main/java/com/jamal/crawler/CrawleLogin.java">源代码</a></p>
<blockquote>
<p>文章不足之处，望大家多多指点，共同学习，共同进步</p>
</blockquote>
<h3 id="最后">最后</h3>
<p>打个小广告，欢迎扫码关注微信公众号：「平头哥的技术博文」，一起进步吧。<br />
<img src="./images/Java 爬虫遇到需要登录的网站，该怎么办？5.png" alt="平头哥的技术博文" /></p>


</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>